{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating PMFs with AWH in GROMACS <a id='another_cell'></a>\n",
    "Here we learn how to calculate the potential of mean force\n",
    "(PMF) along a reaction coordinate (RC) using the accelerated weight\n",
    "histogram method (AWH) in GROMACS.  We will go through both how to set\n",
    "up the input files needed, as well as how to extract and analyze the\n",
    "output after having run the simulation. For more information about\n",
    "the AWH method itself and how it can be used we refer to \\cite{}[TODO how cite?].\n",
    "What you need to know right now is that AWH applies a time-dependent bias\n",
    "potential along the chosen RC, which is tuned during the simulation\n",
    "such that it \"flattens\" the barriers in the PMF to improve sampling along the RC.\n",
    "With better sampling, the PMF can be calculated more accurately than using unbiased MD. [TODO Movie/figure?]\n",
    "\n",
    "*Author: Viveca Lindahl   \n",
    "Email: vivecal@kth.se*\n",
    "\n",
    "## Prerequisites\n",
    "This tutorial assumes you have/know\n",
    "* basic knowledge of using a Linux shell \n",
    "* basic usage of the molecular visualization tool VMD\n",
    "* an installation of GROMACS 2018.1 (available as gmx in your PATH)\n",
    "* python modules numpy, matplotlib\n",
    "\n",
    "## The case study: DNA base pair opening\n",
    "We will calculate a PMF for opening a DNA base\n",
    "pair. The DNA double helix is a very stable structure. Opening a base pair\n",
    "requires breaking hydrogen bonds between the bases and crossing a high free energy\n",
    "barrier.  That's why we need to enhance the sampling by applying a bias!\n",
    "<img src=\"figs/dna-helix.png\" alt=\"dna\" style=\"height: 300px;\"/>\n",
    "As our RC we use the distance between the two atoms forming the central hydrogen-bond the two bases in a pair. Let's have a look at the system and the reaction coordinate using VMD. The `-e` flag below tells VMD to excute the commands that are in the following tcl-script. These commands change how the system is visually represented. For instance, we have hidden all the water to better see the DNA itself, and we have put punchy colors on the atoms defining the RC of our target base pair. Now run this and VMD should pop up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!vmd visualization/dna-centered.gro -e visualization/representation.tcl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rotate the structure and look for the two (nitrogen) atoms in green. The distance between these will serve as our RC for that base pair.\n",
    "\n",
    "## The MD parameter (.mdp) file \n",
    "We'll assume we have already built and equilibrated the system, so we are almost ready to go. To use AWH we basically just need to add some extra parameters in the mdp file. Go to and check out the directory that has all the run files of our first AWH example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd\n",
    "%cd awh-1d\n",
    "!ls -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the differences between this mdp file for AWH and an mdp file for a vanilla MD simulation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!diff ../template-npt/grompp.mdp grompp.mdp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here '<' refers to the content of the first argument to `diff` (the NPT mdp) and '>' to the second (AWH mdp). E.g., we increased the number of steps (`nsteps`) for AWH. The more relevant parameters are the ones prefixed `pull` and `awh`. What do these parameters mean? Generally, google \"gromacs documentation\" to find out, but the comments in the mdp file should be enough here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The index (.ndx) file\n",
    "The .mdp file now depends on some definitions of atom groups; we need to have an index file for these. Here our groups are as simple as they get: each group contains a single nitrogen atom. But don't get tempted to edit an index file manually! The traditional tool to use is `gmx make_ndx` and a more general and powerful tool is `gmx select`. We focus on AWH here and provide the index file, and leave the index file generation as an [exercise](#sec:make-index). Double-check that the groups we saw in the mdp file are actually defined in the index file:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!grep -A 1  N1orN3  index.ndx  # '-A 1' to show also 1 line after the match "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One atom per group looks right. In a real study, a better check would be to visualize these atom indices (e.g. with VMD)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting and analyzing the simulation\n",
    "Now generate the tpr as usual with `grompp` (assuming default naming of input files grompp.mdp, conf.gro, topol.top, index.ndx) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!gmx grompp -n -quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the log file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the values of the pull coordinate values in the provided .gro file are printed by grompp. Does it look reasonable? We now assume we have run a simulation using the. Some information related to the AWH initial convergence can be found in the `mdrun` log file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!grep 'covering' data/md.log\n",
    "!grep 'out of the' data/md.log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the intial stage, the free energy (and bias) update size is kept constant *during* each covering(=transition) across the sampling interval, and decreased in a stepwise manner after each covering.  After exiting the initial stage, the free energy update size will decrease steadily with time. The initial stage is a type of \"burn-in\" process that improves robustness of the method. The idea is to first get a quick and rough estimate in the intitial stage, followed by refinement in the final stage. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The reaction coordinate trajectory\n",
    "The trajectory of the pull coordinate is found in `pullx.xvg`. For a quick look at the contents of such files from the terminal we can use the interactive plotting tool `xmgrace`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -free for nice layout\n",
    "# -nxy to plot multicolumn data\n",
    "!xmgrace -free data/pullx.xvg # wait for it... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function that reads data of an .xvg file\n",
    "def read_xvg(fname):\n",
    "    data=[]\n",
    "    with open(fname) as f: \n",
    "        for line in f:\n",
    "            # Lines with metadata or comments start with #, @\n",
    "            if not line.startswith((\"@\",\"#\")):\n",
    "                data.append(np.array([float(s) for s in line.split()]))\n",
    "    data = np.vstack(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read pullx.xvg file and plot a selected part of the trajectory\n",
    "data = read_xvg(\"data/pullx.xvg\")\n",
    "t, x = data[:,0], data[:,1]\n",
    "tend =5000\n",
    "selection = np.where(t<tend)\n",
    "plt.plot(t[selection], x[selection])\n",
    "ax = plt.gca()\n",
    "# Tweak\n",
    "plt.xlabel(\"time (ns)\")\n",
    "plt.ylabel(\"distance (nm)\");\n",
    "plt.ylim([0.25, 0.65])\n",
    "plt.title('RC trajectory');\n",
    "\n",
    "#texit = 1530\n",
    "#plt.plot([texit,texit],[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify that the covering times correspond to the transition times in the trajectory (assuming the `pullx.xvg` output is frequent enough). Always check this trajectory and make sure that you are observing at least a few transitions after the initial stage. If not, you need to simulate longer or you might have an RC issue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data directly related to AWH is extracted using `gmx awh`. The data is stored in the energy file, `ener.edr`. The output is `awh_t<time>.xvg`; there will be one file for each AWH output time, or less if you use the `-skip` flag. The `-more` flag tells `gmx awh` to more than the PMF from the AWH files, e.g. histograms. The default gmx units of energy is kJ/mol, but with the flag `-kT` we get units of kT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gmx awh -quiet -s topol.tpr -f data/ener.edr -more -kt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a quick look at the contents of these files we can use the click-friendly plotting tool `xmgrace`, which recognizes xvg files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=50000 # ps\n",
    "# -free for nice layout\n",
    "# -nxy to plot multicolumn data\n",
    "!xmgrace -free -nxy awh_t{t}.xvg # wait for it... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The legends in the plot should help understanding what data is being plotted, but here's more:\n",
    "* *PMF*: the free energy estimate along the RC\n",
    "* *Coord bias*: the bias acting on the RC\n",
    "* *Coord distr*: the observed distribution (histogram) of the RC, $\\xi(x)$\n",
    "* *Ref value distr*: weight histogram of reference coordinate value, $\\lambda$\n",
    "* *Target ref value distr*: the target distribution for $\\lambda$ (uniform by default)\n",
    "* Friction metric: a (here unitless) metric for local friction\n",
    "\n",
    "Sanity checks for the distributions:\n",
    "* *Coord distr* $\\approx$ *Ref value distr*, or the force constant in the mdp file is too weak.\n",
    "* *Ref value distr* $\\approx$ *Target ref value distr*, or we may have a poor bias estimate/need to sample longer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look closer at the evolution of the PMF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re # use regular expressions to find matching strings\n",
    "\n",
    "# Plot PMFs from AWH xvg files\n",
    "\n",
    "# A list of all AWH files\n",
    "fnames = !ls awh_t*xvg\n",
    "\n",
    "# Extract time of each file\n",
    "times = [float(re.findall('awh_t(.+?).xvg', fname)[0]) for fname in fnames]\n",
    "\n",
    "# Sort the files chronologically\n",
    "fnames = [f for (t,f) in sorted(zip(times, fnames))]\n",
    "times.sort()\n",
    "print \"Number of files:\", len(fnames)\n",
    "print \"Time in between files \", times[1] - times[0], 'ps'\n",
    "print \"Last time\", times[-1], 'ps'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the PMF from first files/times\n",
    "labels=[]\n",
    "istart = 0  # Start plotting this file index\n",
    "nplot = 10  # Number of files to plot\n",
    "for fname in fnames[istart:istart+nplot]:\n",
    "    data=read_xvg(fname)\n",
    "    labels.append(re.findall('awh_t(.+?).xvg', fname)[0] + ' ps') # use the time as label\n",
    "    plt.plot(data[:,0], data[:,1])\n",
    "plt.xlabel('distance (nm)')\n",
    "plt.ylabel('PMF (kT)')\n",
    "plt.xlim([0.25,0.60])\n",
    "plt.ylim([0,20])\n",
    "plt.legend(labels);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try increasing the `istart` variable above to see how the PMF estimates are changing less and less over time. *Note*: this convergence does not easily translate into error estimates for the PMF. To get such error bars the simplest is to run multiple (independent) AWH simulations and calculate standard errors from there [add exercise?]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the histogram from first files/times\n",
    "labels=[]\n",
    "istart = 1000  # Start plotting this file index\n",
    "nplot = 10  # Number of files to plot\n",
    "for fname in fnames[istart:istart+nplot]:\n",
    "    data=read_xvg(fname)\n",
    "    labels.append(re.findall('awh_t(.+?).xvg', fname)[0] + ' ps') # use the time as label\n",
    "    plt.plot(data[:,0], data[:,3])\n",
    "plt.xlabel('distance (nm)')\n",
    "plt.ylabel('bias()')\n",
    "plt.xlim([0.25,0.60])\n",
    "#plt.ylim([0,20])\n",
    "plt.legend(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's about it for running an AWH simulation in GROMACS!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple bias sharing walkers\n",
    "A simple way of parallelizing AWH is to run multiple simulations, using the `mdrun` flag `-multidir` and have them all share the collected samples and bias potential. This can reduce the length of the initial stage significantly. If we just apply `-multidir` we will get multiple *independent* simulations. We need to add a couple of things in the mdp file to make AWH share information across simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!pwd\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir awh-multi \n",
    "!cp awh-1d/grompp.mdp awh-1d/topol.top awh-1d/index.ndx awh-1d/conf.gro awh-multi\n",
    "!echo \"awh-share-multisim = yes\" >> awh-multi/grompp.mdp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracurricular: effect of changing the force constant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracurricular: effect of changing the diffusion parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracurricular: making an index file  with `gmx select`\n",
    "<a id='sec:make-index'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "but here I'll instead show how to use the flashier and more general tool `gmx select`. Learn about it using `gmx select -h`, as for any gmx command. Alternatively, the same information canbe found in the online GROMACS docs that you hopefully found above. HereFor making and index file we need to provide either a selection file (flag `-sf`) or a selection string (`-select`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo hello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd\n",
    "%ls -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
