{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating PMFs with AWH in GROMACS <a id='another_cell'></a>\n",
    "Here we learn how to calculate the potential of mean force\n",
    "(PMF) along a reaction coordinate (RC) using the accelerated weight\n",
    "histogram method (AWH) in GROMACS.  We will go through both how to set\n",
    "up the input files needed, as well as how to extract and analyze the\n",
    "output after having run the simulation. For more information about\n",
    "the AWH method itself and how it can be used we refer to \\cite{}[TODO how cite?].\n",
    "What you need to know right now is that AWH applies a time-dependent bias\n",
    "potential along the chosen RC, which is tuned during the simulation\n",
    "such that it \"flattens\" the barriers in the PMF to improve sampling along the RC.\n",
    "With better sampling, the PMF can be calculated more accurately than using unbiased MD. [TODO Movie/figure?]\n",
    "\n",
    "*Author: Viveca Lindahl   \n",
    "Email: vivecal@kth.se*\n",
    "\n",
    "## Prerequisites\n",
    "This tutorial assumes you have/know\n",
    "* basic knowledge of using a Linux shell \n",
    "* basic usage of the molecular visualization tool VMD\n",
    "* an installation of GROMACS 2018.1 (available as gmx in your PATH)\n",
    "* python modules numpy, matplotlib\n",
    "\n",
    "## The case study: DNA base pair opening\n",
    "We will calculate a PMF for opening a DNA base\n",
    "pair. The DNA double helix is a very stable structure. Opening a base pair\n",
    "requires breaking hydrogen bonds between the bases and crossing a high free energy\n",
    "barrier.  That's why we need to enhance the sampling by applying a bias!\n",
    "<img src=\"figs/dna-helix.png\" alt=\"dna\" style=\"height: 300px;\"/>\n",
    "As our RC we use the distance between the two atoms forming the central hydrogen-bond the two bases in a pair. Let's have a look at the system and the reaction coordinate using VMD. The `-e` flag below tells VMD to excute the commands that are in the following tcl-script. These commands change how the system is visually represented. For instance, we have hidden all the water to better see the DNA itself, and we have put punchy colors on the atoms defining the RC of our target base pair. Now run this and VMD should pop up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!vmd visualization/dna-centered.gro -e visualization/representation.tcl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rotate the structure and look for the two (nitrogen) atoms in green. The distance between these will serve as our RC for that base pair. Quit VMD to continue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The MD parameter (.mdp) file \n",
    "We'll now assume we have already built and equilibrated the system, so that we are almost ready to go. To use AWH we basically just need to add some extra parameters in the mdp file. Go to and check out the directory that has all the run files of our first AWH example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd awh-simple\n",
    "!ls -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the differences between the mdp file using AWH and an mdp file for a vanilla MD simulation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!diff no-awh.mdp awh.mdp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here '<' refers to the content of the first argument to `diff` (the non-AWH mdp) and '>' to the second (AWH mdp). E.g., we increased the number of steps (`nsteps`) for AWH. The more relevant parameters are the ones prefixed `pull` and `awh`. What do these parameters mean? Generally, google \"gromacs documentation\" to find out, but the comments in the mdp file should be enough here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The index (.ndx) file\n",
    "The .mdp file now depends on some definitions of atom groups; we need to have an index file for these. Here our groups are as simple as they get: each group contains a single nitrogen atom. But don't get tempted to edit an index file manually! The traditional tool to use is `gmx make_ndx` and a more general and powerful tool is `gmx select`. We focus on AWH here and provide the index file. Double-check that the pull groups (e.g. `pull-group1-name`) we saw in the mdp file are actually defined in the index file:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!grep -A 1  N1orN3  index.ndx  # '-A 1' to show also 1 line after the match "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One atom per group looks right. In a real study, a better check would be to visualize the atom indices (e.g. with VMD)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting the simulation\n",
    "Here we won't run the actual simulation; a directory with data has already been provided. But for practice, we will generate a tpr, as usual with `grompp`. The flag `-quiet` tells `grompp` to be less verbose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!gmx grompp -quiet -f awh.mdp -n index.ndx -p topol.top -o topol.tpr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the values of the pull coordinate values in the provided .gro file are printed by `grompp`. Does it look reasonable? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the log file\n",
    "Now let's look at the data we've provided. Some information related to the AWH initial convergence can be found in the `mdrun` log file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!grep 'covering' data/md.log\n",
    "!grep 'out of the' data/md.log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the AWH intial stage, the free energy (and bias) update size is kept constant *during* each transition of the sampling interval, and decreased in a stepwise manner after the interval has been covered.  After exiting the initial stage, the free energy update size will decrease steadily with time. The initial stage is a type of \"burn-in\" process that improves robustness of the method. The idea is to first get a quick and rough estimate in the intitial stage, followed by refinement in the final stage. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The reaction coordinate trajectory\n",
    "The trajectory of the pull coordinate is found in `pullx.xvg`. For a quick look at the contents of such files from the terminal we can use the interactive plotting tool `xmgrace`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -free for nice layout\n",
    "!xmgrace -free data/pullx.xvg # wait for it... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more serious plotting and data analysis, one can write a small python function to read the xvg file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function that reads data from an .xvg file\n",
    "def read_xvg(fname):\n",
    "    data=[]\n",
    "    with open(fname) as f: \n",
    "        for line in f:\n",
    "            # Lines with metadata or comments start with #, @\n",
    "            if not line.startswith((\"@\",\"#\")):\n",
    "                data.append(np.array([float(s) for s in line.split()]))\n",
    "    data = np.vstack(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can for instance plot the covering times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read pullx.xvg file and plot a selected part of the trajectory\n",
    "data = read_xvg(\"data/pullx.xvg\")\n",
    "t, x = data[:,0], data[:,1]\n",
    "plt.plot(t, x)\n",
    "ax = plt.gca()\n",
    "\n",
    "# Tweak\n",
    "plt.ylim([0.25, 0.65])\n",
    "tend =10000\n",
    "plt.xlim([0,tend])\n",
    "plt.xlabel(\"time (ns)\")\n",
    "plt.ylabel(\"distance (nm)\");\n",
    "plt.title('RC trajectory');\n",
    "\n",
    "# Find covering times and plot them\n",
    "# Extract substrings using regular expressions\n",
    "import re\n",
    "\n",
    "covering_logs = !grep covering data/md.log\n",
    "covering_times = [float(re.findall('t = (.+?) ps', log)[0]) for  log in covering_logs]\n",
    "for tcover in covering_times:\n",
    "    plt.plot([tcover,tcover],[0,1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify that the covering times coincide roughly with the transition times in the trajectory. What we expect to see here is that the covering time is shorter initially, when the the bias fluctuates more, and then the transitions times increase as the bias stops changing. You should always check this trajectory and make sure that there are at least a few transitions after the initial stage. If not, you need to simulate longer or you might have an RC issue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The `gmx awh` tool and the `awh.xvg` files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data directly related to AWH is extracted using `gmx awh`. The data is stored in the energy file, `ener.edr`. The default output is `awh_t<time>.xvg`; there will be one file for each AWH output time, or less if you use the `-skip` flag. Let's dump the output into a separate directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p awh-data\n",
    "!gmx awh -quiet -s topol.tpr -f data/ener.edr -more -kt -o awh-data/awh.xvg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, the `-more` flag tells `gmx awh` to more than the PMF from the AWH files, e.g. histograms. The default gmx units of energy is kJ/mol, but with the flag `-kT` we get units of kT."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a click look at the contents of one of these files (from time 50 ns) using `xmgrace`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=50000 # ps\n",
    "# -nxy to plot multicolumn data\n",
    "!xmgrace -free -nxy awh-data/awh_t{t}.xvg # wait for it... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The legends in the plot should help understanding what data is being plotted. In more detail:\n",
    "* *PMF*: the free energy estimate along the RC,  $\\xi(x)$.\n",
    "* *Coord bias*: the bias acting on  $\\xi$. Note: $\\xi$ is attracted to large values of the bias.\n",
    "* *Coord distr*: histogram of  $\\xi$.\n",
    "* *Ref value distr*: probability weight histogram of reference coordinate value, $\\lambda$.\n",
    "* *Target ref value distr*: the target distribution for $\\lambda$ (uniform by default).\n",
    "* Friction metric: a metric for local friction, or 1/diffusion (here unitless). Can pinpoint hard-to-sample regions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sanity checks for the distributions (zoom in to see them better)**\n",
    "* *Coord distr* $\\approx$ *Ref value distr*, or the force constant in the mdp file may is too weak there.\n",
    "\n",
    "Note that for the smallest distances, where atoms are repelling each other and the PMF is steep, this doesn't hold entirely! But this is not an important sampling region for us. \n",
    "\n",
    "* *Ref value distr* $\\approx$ *Target ref value distr*, i.e. that what we sampled is close to the distribution that we targeted. If not true, we may have a poor bias estimate/need to sample longer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look closer at the evolution of the PMF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot PMFs from AWH xvg files\n",
    "\n",
    "# A list of all AWH files\n",
    "fnames = !ls awh-data/awh_t*xvg\n",
    "\n",
    "# Extract time of each file\n",
    "times = [float(re.findall('awh_t(.+?).xvg', fname)[0]) for fname in fnames]\n",
    "\n",
    "# Sort the files chronologically\n",
    "fnames = [f for (t,f) in sorted(zip(times, fnames))]\n",
    "times.sort()\n",
    "print \"Number of files:\", len(fnames)\n",
    "print \"Time in between files \", times[1] - times[0], 'ps'\n",
    "print \"Last time\", times[-1], 'ps'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the PMF from first files/times\n",
    "labels=[]\n",
    "istart = 0 # Start plotting this file index\n",
    "nplot = 10  # Number of files to plot\n",
    "for fname in fnames[istart:istart+nplot]:\n",
    "    data=read_xvg(fname)\n",
    "    labels.append(re.findall('awh_t(.+?).xvg', fname)[0] + ' ps') # use the time as label\n",
    "    plt.plot(data[:,0], data[:,1])\n",
    "plt.xlabel('distance (nm)')\n",
    "plt.ylabel('PMF (kT)')\n",
    "plt.xlim([0.25,0.60])\n",
    "plt.ylim([0,20])\n",
    "plt.legend(labels);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try increasing the `istart` variable above to see how the PMF estimates are changing (less and less) over time. *Note*: this convergence does not easily translate into error estimates for the PMF. To get such error bars the simplest is to run multiple (independent) AWH simulations and calculate standard errors from that [add exercise?]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's about what's needed for running a AWH simulation in GROMACS!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple bias sharing walkers\n",
    "A simple way of parallelizing AWH is to run multiple simulations, using the `mdrun` flag `-multidir` and have them all share the collected samples and bias potential. This can reduce the length of the initial stage significantly. If we just apply `-multidir` we will get multiple *independent* simulations. We need to add a couple of things in the mdp file to make AWH share information across simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%cd ../awh-multi;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!diff ../awh-simple/awh.mdp awh-multi.mdp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These options tells `gmx mdrun` to share AWH biases across simulations when using `gmx mdrun -multidir`, and which AWH biases should be communicating with which (here there is only one bias, indexed by 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
